{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\") #Makes imshow work on mac\n",
    "from matplotlib import pyplot as plt\n",
    "from Model import Model, draw_boxes\n",
    "import collections\n",
    "import LanguageModel\n",
    "import cozmo\n",
    "import pickle\n",
    "import sys\n",
    "import queue\n",
    "import time\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import csv\n",
    "import base64\n",
    "from ImageFeatureGen import ImageFeatureGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectImages():\n",
    "    print('Detect Images started')\n",
    "    global prediction\n",
    "    \n",
    "    while(True):\n",
    "#         print('image queue empty? ', imageQueue.empty())\n",
    "        if(not imageQueue.empty()):\n",
    "#             try:\n",
    "#                 print('length of image buffer? ', len(imageBuffer))\n",
    "                if len(imageBuffer) < 8:\n",
    "                    plt.clf() # We need to clear the plot so that we are not plotting every image each iteration. (If we don't we will get increasing delay)\n",
    "\n",
    "                    pilImg = imageQueue.get()\n",
    "                    box, imgResized = model.object_detect(pilImg.copy())\n",
    "                    cleanImg = imgResized.copy();\n",
    "                    draw_boxes(box, imgResized, (model.size, model.size))\n",
    "\n",
    "                    imgWithBox = np.array(imgResized) \n",
    "                    #imgWithBox = imgWithBox[:, :, ::-1].copy()\n",
    "                    box = box[0]\n",
    "                    formattedBox = (box[1], box[0], box[3], box[2]) # coordinates need to be corrected for crop\n",
    "\n",
    "                    croppedImg = cleanImg.crop(formattedBox)\n",
    "                    croppedImg = np.array(croppedImg) \n",
    "                    croppedImg = croppedImg[:, :, ::-1].copy()\n",
    "\n",
    "                    imgNumpy = np.asarray(pilImg)\n",
    "                    imgStr = base64.b64encode(imgNumpy)\n",
    "                    imgStr = str(imgStr)[2:-1]\n",
    "\n",
    "                    dimensions = list(pilImg.size)[::-1] + [3]\n",
    "\n",
    "#                     imgStr = imgStr.replace('] [', '], [')\n",
    "\n",
    "                    row = [imgStr, prediction, dimensions, formattedBox, croppedImg]\n",
    "\n",
    "                    if len(imageBuffer) < 8:\n",
    "                        imageBuffer.append(row)\n",
    "\n",
    "                    plt.imshow(imgWithBox)\n",
    "                    plt.pause(0.001) # imshow needs time to plot the image. Need this to display the image\n",
    "\n",
    "                else:\n",
    "#                     print('predict? ', predicting)\n",
    "                    if prediction is '' or predicting:\n",
    "                        print('prediction? ', prediction)\n",
    "                        if not imageQueue.empty():\n",
    "\n",
    "                            predict()\n",
    "#             except queue.Empty:\n",
    "#                 pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "search a list, return list of indices where the object matches the search item \n",
    "'''\n",
    "def list_search(haystack: list, needle: object):\n",
    "    matches = []\n",
    "    i = 0\n",
    "    for hay in haystack:\n",
    "        if hay == needle:\n",
    "            matches.append(i)\n",
    "        else:\n",
    "            i+=1\n",
    "            continue\n",
    "    return matches\n",
    "            \n",
    "'''\n",
    "Return a list of only those objects existing in the list specified indices\n",
    "'''\n",
    "def slice_indices(indices: list, unsliced: list):\n",
    "    sliced = []\n",
    "    for i in indices:\n",
    "        save = unsliced[i]\n",
    "        sliced.append(save)\n",
    "    return sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    global speak\n",
    "    global prediction\n",
    "    \n",
    "    print('Predict!')\n",
    "    \n",
    "    preds = []\n",
    "    rows = []\n",
    "    for i in range(len(imageBuffer)):\n",
    "        row = imageBuffer.pop()\n",
    "        currentImg = row[4]\n",
    "        preds.append(predModel.predictImageWord(currentImg))\n",
    "    \n",
    "        rows.append(row)\n",
    "        \n",
    "    # each prob is a tuple ( word, probability )\n",
    "    preds = [item[0] for item in preds] #remove probability number in tuple\n",
    "    \n",
    "    prediction = collections.Counter(preds).most_common(1)[0][0]\n",
    "    \n",
    "    best_guesses = list_search(preds, prediction)\n",
    "    best_rows = slice_indices(best_guesses, rows)\n",
    "    \n",
    "    print('preds: ', preds)\n",
    "    # change feedback once back to cozmo_program and user has been queried\n",
    "    feedback = -1\n",
    "    for r in best_rows:\n",
    "        # img\n",
    "        imgStr = r[0]\n",
    "        dimensions = r[2]\n",
    "        buffer = base64.b64decode(imgStr)\n",
    "        img = np.frombuffer(buffer, dtype= np.uint8).reshape(tuple(dimensions))\n",
    "        # prediction\n",
    "        # box_coord\n",
    "        box_coord = r[3]\n",
    "        # time\n",
    "        time = str(datetime.datetime.now()) #[10:]\n",
    "        # feedback\n",
    "        # imgFeatures\n",
    "        featureGen = ImageFeatureGen()\n",
    "        imgFeatures = featureGen.getFeatures(img)\n",
    "        \n",
    "        row = (img, prediction, box_coord, time, feedback, imgFeatures)\n",
    "        exploitHistory.append(row)\n",
    "    \n",
    "    speak = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   This is running predict on EVERY image in the image buffer...\n",
    "    so this could be up to 8 different images, and then taking\n",
    "    the median guess.\n",
    "    ...\n",
    "    so how to save these image features?\n",
    "...\n",
    "    different policies:\n",
    "    --> only make a prediction if the guess is UNANIMOUS ?\n",
    "    --> run down the list if made an incorrect prediction ?\n",
    "    --> ask user for label; predict that label on the image; \n",
    "    DEPENDING on probability, THAT will affect how much \n",
    "    cozmo's confidence DECREASES. \n",
    "...\n",
    "    OR, if that label is NOT in the dataset at all, \n",
    "    cozmo's confidence starts out at 0 for that word. \n",
    "    [overall confidence + discrete / word-level confidences]\n",
    "...\n",
    "    add value of prediction to the row that will be\n",
    "    given to the 'exploit' dataset now that it has been called\n",
    "    in the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def key_listener():\n",
    "#     global predicting\n",
    "#     while predicting: #True:  \n",
    "# #         predicting = True\n",
    "        \n",
    "# #         if not imageQueue.empty():\n",
    "#         print('Predict!')\n",
    "# #         response = sys.stdin.readline()\n",
    "# #        response = input()\n",
    "\n",
    "#         # if confidence > threshold:\n",
    "# #        if response.strip() == 'y':\n",
    "#         if predicting:\n",
    "#             predict()\n",
    "#             predicting = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_image(evt, obj=None, tap_count=None,  **kwargs):\n",
    "    try:\n",
    "#         print('image handled')\n",
    "        if(imageQueue.empty()):\n",
    "            imageQueue.put_nowait(evt.image)\n",
    "    except queue.Full:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save a history of this exploit attempt;\n",
    "including:\n",
    "Cozmo's prediction; \n",
    "user's feedback\n",
    "'''\n",
    "def exploit_history(feedback: int):\n",
    "    ds = []\n",
    "    for i in range(len(exploitHistory)):\n",
    "        r = exploitHistory.pop()\n",
    "        row = list(r)\n",
    "        row[4] = feedback\n",
    "        row = tuple(row)\n",
    "        ds.append(row)\n",
    "\n",
    "    datafr = pd.DataFrame(ds, columns=['img','prediction','box_coord','time','feedback','imgFeatures'])\n",
    "    datafr.to_csv(exploit_dataset, index=False)\n",
    "    print('save feedback')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cozmo_program(robot: cozmo.robot.Robot):\n",
    "    robot.set_lift_height(1.0).wait_for_completed()\n",
    "    robot.camera.color_image_enabled = True\n",
    "    robot.add_event_handler(cozmo.camera.EvtNewRawCameraImage, handle_image)\n",
    "    print(\"Added event handler\")\n",
    "    #robot.say_text(\"purple\").wait_for_completed()\n",
    "    \n",
    "    while True:\n",
    "        global predicting \n",
    "        global speak\n",
    "        global feedback\n",
    "        if speak == True:\n",
    "            print('Speak!')\n",
    "            robot.say_text(prediction).wait_for_completed()\n",
    "            print('??? [1 or 0]')\n",
    "            feedback = input()\n",
    "            exploit_history(int(feedback))\n",
    "            speak = False\n",
    "            predicting = True\n",
    "            print('predict again? ', predicting)\n",
    "\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>prediction</th>\n",
       "      <th>box_coord</th>\n",
       "      <th>time</th>\n",
       "      <th>feedback</th>\n",
       "      <th>imgFeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[21 12  7]\\n  [21 12  7]\\n  [27 16 12]\\n  .....</td>\n",
       "      <td>green</td>\n",
       "      <td>(35.60529, 34.4622, 219.33578, 138.15332)</td>\n",
       "      <td>2019-08-07 16:53:40.854742</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.35872 0.      0.      ... 2.07018 0.      2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[21 12  7]\\n  [21 12  7]\\n  [27 16 12]\\n  .....</td>\n",
       "      <td>green</td>\n",
       "      <td>(35.60529, 34.4622, 219.33578, 138.15332)</td>\n",
       "      <td>2019-08-07 16:53:32.892345</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.35872 0.      0.      ... 2.07018 0.      2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[21 12  7]\\n  [21 12  7]\\n  [27 16 12]\\n  .....</td>\n",
       "      <td>green</td>\n",
       "      <td>(35.60529, 34.4622, 219.33578, 138.15332)</td>\n",
       "      <td>2019-08-07 16:53:25.132958</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.35872 0.      0.      ... 2.07018 0.      2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[21 12  7]\\n  [21 12  7]\\n  [27 16 12]\\n  .....</td>\n",
       "      <td>green</td>\n",
       "      <td>(35.60529, 34.4622, 219.33578, 138.15332)</td>\n",
       "      <td>2019-08-07 16:53:17.346976</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.35872 0.      0.      ... 2.07018 0.      2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[21 12  7]\\n  [21 12  7]\\n  [27 16 12]\\n  .....</td>\n",
       "      <td>green</td>\n",
       "      <td>(35.60529, 34.4622, 219.33578, 138.15332)</td>\n",
       "      <td>2019-08-07 16:53:10.031855</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.35872 0.      0.      ... 2.07018 0.      2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 img prediction  \\\n",
       "0  [[[21 12  7]\\n  [21 12  7]\\n  [27 16 12]\\n  .....      green   \n",
       "1  [[[21 12  7]\\n  [21 12  7]\\n  [27 16 12]\\n  .....      green   \n",
       "2  [[[21 12  7]\\n  [21 12  7]\\n  [27 16 12]\\n  .....      green   \n",
       "3  [[[21 12  7]\\n  [21 12  7]\\n  [27 16 12]\\n  .....      green   \n",
       "4  [[[21 12  7]\\n  [21 12  7]\\n  [27 16 12]\\n  .....      green   \n",
       "\n",
       "                                   box_coord                        time  \\\n",
       "0  (35.60529, 34.4622, 219.33578, 138.15332)  2019-08-07 16:53:40.854742   \n",
       "1  (35.60529, 34.4622, 219.33578, 138.15332)  2019-08-07 16:53:32.892345   \n",
       "2  (35.60529, 34.4622, 219.33578, 138.15332)  2019-08-07 16:53:25.132958   \n",
       "3  (35.60529, 34.4622, 219.33578, 138.15332)  2019-08-07 16:53:17.346976   \n",
       "4  (35.60529, 34.4622, 219.33578, 138.15332)  2019-08-07 16:53:10.031855   \n",
       "\n",
       "   feedback                                        imgFeatures  \n",
       "0         0  [1.35872 0.      0.      ... 2.07018 0.      2...  \n",
       "1         0  [1.35872 0.      0.      ... 2.07018 0.      2...  \n",
       "2         0  [1.35872 0.      0.      ... 2.07018 0.      2...  \n",
       "3         0  [1.35872 0.      0.      ... 2.07018 0.      2...  \n",
       "4         0  [1.35872 0.      0.      ... 2.07018 0.      2...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploit_dataset = 'exploit_history.csv'\n",
    "\n",
    "try:\n",
    "    exploit_data = pd.read_csv(exploit_dataset)\n",
    "except FileNotFoundError:\n",
    "    row = ['img','prediction','box_coord','time','feedback','imgFeatures']\n",
    "\n",
    "    with open(exploit_dataset, 'w') as writeFile:\n",
    "        writer = csv.writer(writeFile)\n",
    "        writer.writerow(row)\n",
    "        \n",
    "exploit_data = pd.read_csv(exploit_dataset)\n",
    "\n",
    "print(len(exploit_data)) \n",
    "exploit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/keras/utils/conv_utils.py:82: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.copy(kernel[slices])\n",
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.20.2 when using version 0.21.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model = Model(path='../f18/data/coco2014', jpegs='../f18/train2014', bb_csv='../f18/data/coco2014/tmp/bb.csv')\n",
    "\n",
    "with open('language-model.pickle', 'rb') as handle:\n",
    "    predModel = pickle.load(handle) #trying to load a LanguageModel type\n",
    "\n",
    "imageQueue = queue.Queue(maxsize=1)\n",
    "# deque: double-ended queue; thread-safe\n",
    "imageBuffer = collections.deque(maxlen=8)\n",
    "\n",
    "exploitHistory = collections.deque(maxlen=8) \n",
    "\n",
    "speak = False\n",
    "predicting = False\n",
    "prediction = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Images started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-07 16:56:18,755 cozmo.general INFO     App connection established. sdk_version=1.4.10 cozmoclad_version=3.4.0 app_build_version=00003.00004.00000\n",
      "2019-08-07 16:56:18,824 cozmo.general INFO     Found robot id=1\n",
      "2019-08-07 16:56:19,137 cozmo.general INFO     Connected to Android device serial=03160355293b2004\n",
      "2019-08-07 16:56:19,210 cozmo.general INFO     Robot id=1 serial=024086a7 initialized OK\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/david/anaconda3/envs/oldfastai/lib/python3.6/tkinter/__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/home/david/anaconda3/envs/oldfastai/lib/python3.6/tkinter/__init__.py\", line 749, in callit\n",
      "    func(*args)\n",
      "  File \"/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/cozmo/tkview.py\", line 164, in _repeat_draw_frame\n",
      "    self._draw_frame()\n",
      "  File \"/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/cozmo/tkview.py\", line 158, in _draw_frame\n",
      "    self.label.configure(image=photoImage)\n",
      "  File \"/home/david/anaconda3/envs/oldfastai/lib/python3.6/tkinter/__init__.py\", line 1485, in configure\n",
      "    return self._configure('configure', cnf, kw)\n",
      "  File \"/home/david/anaconda3/envs/oldfastai/lib/python3.6/tkinter/__init__.py\", line 1476, in _configure\n",
      "    self.tk.call(_flatten((self._w, cmd)) + self._options(cnf))\n",
      "_tkinter.TclError: image \"pyimage1\" doesn't exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added event handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/GIT/cs481-senior-design/s19/Model.py:87: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  scipy.misc.imsave(tempFile, img_resized)\n",
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/scipy/misc/pilutil.py:217: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "  im = toimage(arr, channel_axis=2)\n",
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/scipy/misc/pilutil.py:381: DeprecationWarning: `bytescale` is deprecated!\n",
      "`bytescale` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "  bytedata = bytescale(data, high=high, low=low, cmin=cmin, cmax=cmax)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction?  \n",
      "Predict!\n",
      "preds:  ['orange', 'orange', 'orange', 'orange', 'orange', 'green', 'orange', 'orange']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/keras/utils/conv_utils.py:82: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.copy(kernel[slices])\n",
      "/home/david/GIT/cs481-senior-design/s19/Model.py:87: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  scipy.misc.imsave(tempFile, img_resized)\n",
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/scipy/misc/pilutil.py:217: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "  im = toimage(arr, channel_axis=2)\n",
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/scipy/misc/pilutil.py:381: DeprecationWarning: `bytescale` is deprecated!\n",
      "`bytescale` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "  bytedata = bytescale(data, high=high, low=low, cmin=cmin, cmax=cmax)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak!\n",
      "??? [1 or 0]\n",
      "0\n",
      "save feedback\n",
      "predict again?  True\n",
      "prediction?  orange\n",
      "Predict!\n",
      "preds:  ['orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'purple']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/keras/utils/conv_utils.py:82: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.copy(kernel[slices])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/GIT/cs481-senior-design/s19/Model.py:87: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  scipy.misc.imsave(tempFile, img_resized)\n",
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/scipy/misc/pilutil.py:217: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "  im = toimage(arr, channel_axis=2)\n",
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/scipy/misc/pilutil.py:381: DeprecationWarning: `bytescale` is deprecated!\n",
      "`bytescale` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "  bytedata = bytescale(data, high=high, low=low, cmin=cmin, cmax=cmax)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction?  orange\n",
      "Predict!\n",
      "??? [1 or 0]\n",
      "preds:  ['orange', 'green', 'orange', 'orange', 'orange', 'orange', 'orange', 'purple']\n",
      "0\n",
      "save feedback\n",
      "predict again?  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/keras/utils/conv_utils.py:82: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.copy(kernel[slices])\n",
      "/home/david/GIT/cs481-senior-design/s19/Model.py:87: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  scipy.misc.imsave(tempFile, img_resized)\n",
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/scipy/misc/pilutil.py:217: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "  im = toimage(arr, channel_axis=2)\n",
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/scipy/misc/pilutil.py:381: DeprecationWarning: `bytescale` is deprecated!\n",
      "`bytescale` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "  bytedata = bytescale(data, high=high, low=low, cmin=cmin, cmax=cmax)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak!\n",
      "prediction?  orange\n",
      "Predict!\n",
      "??? [1 or 0]\n",
      "preds:  ['orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange']\n",
      "0\n",
      "save feedback\n",
      "predict again?  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/keras/utils/conv_utils.py:82: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.copy(kernel[slices])\n",
      "/home/david/GIT/cs481-senior-design/s19/Model.py:87: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  scipy.misc.imsave(tempFile, img_resized)\n",
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/scipy/misc/pilutil.py:217: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "  im = toimage(arr, channel_axis=2)\n",
      "/home/david/anaconda3/envs/oldfastai/lib/python3.6/site-packages/scipy/misc/pilutil.py:381: DeprecationWarning: `bytescale` is deprecated!\n",
      "`bytescale` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "  bytedata = bytescale(data, high=high, low=low, cmin=cmin, cmax=cmax)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak!\n",
      "prediction?  orange\n",
      "Predict!\n",
      "??? [1 or 0]\n",
      "preds:  ['green', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-07 17:00:22,889 cozmo.general INFO     Shutting down connection\n",
      "2019-08-07 17:00:22,890 cozmo.general INFO     Android serial=03160355293b2004 disconnected.\n",
      "2019-08-07 17:00:22,891 cozmo.general INFO     Exit requested by user\n"
     ]
    }
   ],
   "source": [
    "threading.Thread(target=detectImages).start()\n",
    "# threading.Thread(target=key_listener).start()\n",
    "\n",
    "cozmo.run_program(cozmo_program, use_viewer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the language model that we'll be appending to w/ exploit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_df = pd.read_pickle('language-model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LanguageModel' object has no attribute 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ababa645a027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LanguageModel' object has no attribute 'df'"
     ]
    }
   ],
   "source": [
    "lm_df.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
